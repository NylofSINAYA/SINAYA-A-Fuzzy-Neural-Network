{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNEJojAWhxw9s86Y2CTtCs0",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/frfrsimp/SINAYA-A-Fuzzy-Neural-Network/blob/main/SINAYA_Project.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QiFNNNj3UYOS"
      },
      "outputs": [],
      "source": [
        "!pip install tensorflow numpy pandas"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from keras import optimizers\n",
        "from tensorflow.keras.metrics import Accuracy, MeanSquaredError\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "\n",
        "# Load the training data from a CSV file\n",
        "data = pd.read_csv(\"/content/Training Dataset v2.csv\")\n",
        "\n",
        "# Normalize the input and output data\n",
        "scaler = MinMaxScaler()\n",
        "X = scaler.fit_transform(data[[\"pH\", \"do\", \"temp\"]])\n",
        "y = scaler.fit_transform(data[[\"ammonia\"]])\n",
        "\n",
        "# Define the input layers\n",
        "input_pH = tf.keras.layers.Input(shape=(1,))\n",
        "input_do = tf.keras.layers.Input(shape=(1,))\n",
        "input_temp = tf.keras.layers.Input(shape=(1,))\n",
        "\n",
        "# Define the fuzzy membership functions\n",
        "pH = tf.keras.layers.Lambda(lambda x: tf.clip_by_value(tf.pow(tf.subtract(tf.divide(x, 6.96), 0.765), 3), 0, 1))(input_pH)\n",
        "do = tf.keras.layers.Lambda(lambda x: tf.clip_by_value(tf.pow(tf.divide(tf.subtract(x, 0.26), 7.3), 2), 0, 1))(input_do)\n",
        "temp = tf.keras.layers.Lambda(lambda x: tf.clip_by_value(tf.divide(tf.subtract(x, 29.06), 3.27), 0, 1))(input_temp)\n",
        "\n",
        "# Concatenate the fuzzy membership functions\n",
        "concat = tf.keras.layers.Concatenate()([pH, do, temp])\n",
        "\n",
        "# Define the fuzzy rule base\n",
        "rule1 = tf.keras.layers.Lambda(lambda x: tf.minimum(x[0], x[1]))([pH, do])\n",
        "rule2 = tf.keras.layers.Lambda(lambda x: tf.minimum(x[0], x[1]))([do, temp])\n",
        "rule3 = tf.keras.layers.Lambda(lambda x: tf.minimum(x[0], x[1]))([pH, temp])\n",
        "rule4 = tf.keras.layers.Lambda(lambda x: tf.minimum(x[0], tf.minimum(x[1], x[2])))([pH, do, temp])\n",
        "rule5 = tf.keras.layers.Lambda(lambda x: tf.minimum(x[0], x[1]))([pH, tf.subtract(1.0, do)])\n",
        "rule6 = tf.keras.layers.Lambda(lambda x: tf.minimum(x[0], tf.subtract(1.0, tf.clip_by_value(x[1], 0, 1))))([tf.subtract(1.0, pH), temp])\n",
        "rule7 = tf.keras.layers.Lambda(lambda x: tf.minimum(x[0], tf.subtract(1.0, x[1])))([do, tf.subtract(1.0, pH)])\n",
        "rule8 = tf.keras.layers.Lambda(lambda x: tf.minimum(x[0], tf.subtract(1.0, x[1])))([temp, pH])\n",
        "\n",
        "# Concatenate the rules\n",
        "\n",
        "# Concatenate the rules\n",
        "rules = tf.keras.layers.Concatenate()([rule1, rule2, rule3, rule4])\n",
        "\n",
        "# Define the output layer\n",
        "output = tf.keras.layers.Dense(1, activation='linear')(rules)\n",
        "\n",
        "# Define the neural network model\n",
        "model = tf.keras.models.Model(inputs=[input_pH, input_do, input_temp], outputs=output)\n",
        "\n",
        "# Train the model\n",
        "model = Sequential()\n",
        "model.add(Dense(10, input_shape=(3,), activation='relu'))\n",
        "model.add(Dense(10, activation='sigmoid'))\n",
        "model.add(Dense(10, activation='relu'))\n",
        "model.add(Dense(1, activation='linear'))\n",
        "model.compile(optimizer='nadam', loss='mse', metrics=['accuracy'])\n",
        "optimizer = optimizers.Nadam(learning_rate=0.001, beta_1=0.6, beta_2=0.665, epsilon=7e-08)\n",
        "model.fit(x=X, y=y, epochs=3000, batch_size=64)\n",
        "# Save the model\n",
        "model.save('SINAYA_FFNN_FINAL4.h5')"
      ],
      "metadata": {
        "id": "2LrI_WBFW6uS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import r2_score, mean_absolute_error\n",
        "\n",
        "# Evaluate the model on the training set\n",
        "mse, accuracy = model.evaluate(X, y)\n",
        "\n",
        "y_pred = model.predict(X)\n",
        "r2 = r2_score(y, y_pred)\n",
        "mae = mean_absolute_error(y, y_pred)\n",
        "print(\"R^2:\", r2)\n",
        "print(\"MAE:\", mae)\n",
        "print(\"MSE on training set:\", mse)\n",
        "print('Accuracy on test set:', accuracy)\n",
        "\n",
        "# Load the validation data from a CSV file\n",
        "data2 = pd.read_csv(\"/content/Validation Dataset v2.csv\")\n",
        "\n",
        "# Normalize the input\n",
        "X = scaler.fit_transform(data[[\"pH\", \"do\", \"temp\"]])\n",
        "x1 = data2[[\"pH\", \"do\", \"temp\"]]\n",
        "input_data = scaler.transform(x1)\n",
        "\n",
        "# Feed the input data to the model and get the output\n",
        "output = model.predict(input_data)\n",
        "\n",
        "# Do something with the output\n",
        "output = output * (7.44 - 0.16) + 0.16\n",
        "print(output)"
      ],
      "metadata": {
        "id": "Qpnku9pfYbtL"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}